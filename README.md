# Instituto de Monitoreo y Detecci√≥n de Anomal√≠as en Din√°mica Inmobiliaria en Colombia

[![Python](https://img.shields.io/badge/python-3.12%2B-blue.svg)](https://www.python.org/)

## üìã Tabla de Contenidos

- [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
- [Objetivos](#-objetivos)
- [Stack Tecnol√≥gico](#-stack-tecnol√≥gico)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Flujo de Datos (ETL)](#-flujo-de-datos-etl)
- [Estructura del Dataset](#-estructura-del-dataset)
- [Estado por Fases](#-estado-por-fases)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso](#-uso)
- [Notas Importantes](#-notas-importantes)
- [Autores](#autores)

---

## üìã Descripci√≥n del Proyecto

Sistema de an√°lisis y detecci√≥n de anomal√≠as en transacciones inmobiliarias en Colombia, utilizando datos hist√≥ricos del IGAC (Instituto Geogr√°fico Agust√≠n Codazzi) del per√≠odo 2015-2025. El proyecto tiene como objetivo identificar patrones irregulares en el mercado inmobiliario que puedan indicar fraude, lavado de activos o manipulaci√≥n de precios.

## üéØ Objetivos

- **Monitoreo continuo**: An√°lisis de ~34 millones de registros de transacciones inmobiliarias
- **Detecci√≥n de anomal√≠as**: Identificaci√≥n de patrones irregulares en precios, vol√∫menes y comportamientos
- **Normalizaci√≥n de datos**: Estandarizaci√≥n de informaci√≥n para an√°lisis comparativo entre regiones y per√≠odos
- **An√°lisis temporal**: Seguimiento de la evoluci√≥n del mercado inmobiliario colombiano

Este repositorio implementa de forma incremental las **fases definidas en `docs/task.md`**, apoy√°ndose en la descripci√≥n general de objetivos en `docs/documentation.md`.

## üõ†Ô∏è Stack Tecnol√≥gico

### Procesamiento de Datos

- **Python 3.8+**: Lenguaje principal para an√°lisis y procesamiento
- **Polars**: Manejo eficiente de grandes vol√∫menes de datos (34M+ filas)
- **Pandas**: Para operaciones que requieran compatibilidad con bibliotecas espec√≠ficas
- **SQLAlchemy**: Para consultas y operaciones con bases de datos

### An√°lisis y Visualizaci√≥n

- **Matplotlib/Seaborn**: Visualizaci√≥n de datos
- **Plotly**: Visualizaciones interactivas
- **Scikit-learn**: Modelos de machine learning y detecci√≥n de anomal√≠as
- **NLTK/Spacy**: Procesamiento de lenguaje natural para an√°lisis de texto

### Herramientas de Desarrollo

- **Jupyter Notebooks**: Para an√°lisis exploratorios y documentaci√≥n ejecutable
- **Poetry**: Gesti√≥n de dependencias
- **Git**: Control de versiones

## üîÑ Flujo de Datos (ETL)

Resumen del recorrido de los datos desde la fuente cruda hasta el dataset estandarizado listo para an√°lisis:

1. **Datos crudos (`data/raw/`)**
   - Descarga del hist√≥rico de transacciones inmobiliarias 2015‚Äì2025 (~34M registros) desde la fuente del IGAC.
   - Formato original (CSV u otro) sin limpieza.

2. **Dataset limpio (`data/processed/igac_cleaned.parquet`)**
   - Generado en el notebook `02_limpieza_datos.ipynb` usando `etl.data_cleaner.apply_all_cleaning`.
   - Operaciones clave:
     - Limpieza de columnas string y normalizaci√≥n de municipios/departamentos.
     - Estandarizaci√≥n de fechas a formato `dd/mm/YYYY`.
     - Limpieza de valores num√©ricos (incluyendo `VALOR`).
     - Manejo de nulos e imputaciones espec√≠ficas (folios, n√∫meros catastrales).
     - Eliminaci√≥n de duplicados por `PK`.
   - Formato **Parquet** optimizado para lectura con Polars (aprox. decenas de GB, seg√∫n compresi√≥n).

3. **Dataset estandarizado (`data/processed/igac_standardized.parquet`)**
   - Generado en el notebook `03_estandarizacion.ipynb` usando `etl.normalizer.apply_all_standardization`.
   - Operaciones clave:
     - C√°lculo de `VALOR_AJUSTADO` por inflaci√≥n usando `IPC_DATA` y `BASE_YEAR`.
     - Creaci√≥n de campos temporales derivados (`MES_RADICA`, `TRIMESTRE_RADICA`, etc.).
     - Generaci√≥n de clave geogr√°fica `GEO_KEY = DEPARTAMENTO_MUNICIPIO`.
   - Este dataset es la base para:
     - Reglas de negocio y Z-Score (Fase 2).
     - Modelos de ML y an√°lisis geoespacial (fases posteriores).

## üìä Estructura del Dataset

### Campos Principales

| Campo | Descripci√≥n |
|-------|-------------|
| `PK` | Identificador √∫nico |
| `MATRICULA` | N√∫mero de matr√≠cula inmobiliaria |
| `FECHA_RADICA_TEXTO` | Fecha de radicaci√≥n |
| `FECHA_APERTURA_TEXTO` | Fecha de apertura |
| `YEAR_RADICA` | A√±o de radicaci√≥n |
| `ORIP` | Oficina de Registro de Instrumentos P√∫blicos |
| `DIVIPOLA` | C√≥digo de divisi√≥n pol√≠tico-administrativa |
| `DEPARTAMENTO` | Departamento |
| `MUNICIPIO` | Municipio |
| `TIPO_PREDIO_ZONA` | Tipo de predio y zona |
| `CATEGORIA_RURALIDAD` | Categor√≠a rural/urbana |
| `NUM_ANOTACION` | N√∫mero de anotaci√≥n |
| `ESTADO_FOLIO` | Estado del folio |
| `FOLIOS_DERIVADOS` | Folios derivados |
| `Din√°mica_Inmobiliaria` | Tipo de din√°mica |
| `COD_NATUJUR` | C√≥digo naturaleza jur√≠dica |
| `NOMBRE_NATUJUR` | Nombre naturaleza jur√≠dica |
| `NUMERO_CATASTRAL` | N√∫mero catastral actual |
| `NUMERO_CATASTRAL_ANTIGUO` | N√∫mero catastral anterior |
| `DOCUMENTO_JUSTIFICATIVO` | Documento justificativo |
| `COUNT_A` | Contador A |
| `COUNT_DE` | Contador DE |
| `PREDIOS_NUEVOS` | Indicador de predios nuevos |
| `TIENE_VALOR` | Indicador de valor presente |
| `TIENE_MAS_DE_UN_VALOR` | Indicador de m√∫ltiples valores |
| `VALOR` | Valor de la transacci√≥n (campo num√©rico principal para an√°lisis) |

---

## üö¶ Estado por Fases (seg√∫n `docs/task.md`)

### ‚úÖ Fase 1: Cimientos de Datos y "Zona Cero"

**Estado**: ‚úÖ Implementada en los notebooks `02_limpieza_datos.ipynb` y `03_estandarizacion.ipynb` (parte de OE1).

#### Actividades principales

- [x] **Ingesta y carga eficiente**:
  - Uso de `Polars` en modo *lazy* para cargar ~30M de registros (`load_full_dataset_lazy`).
  - Exploraci√≥n de esquema y conteo de nulos por columna sin cargar todo en memoria.
- [x] **Limpieza inicial de datos** (notebook `02_limpieza_datos.ipynb` + `etl/data_cleaner.apply_all_cleaning`):
  - Eliminaci√≥n de comillas dobles en columnas de texto.
  - Manejo de columnas con alta proporci√≥n de nulos.
  - Depuraci√≥n de columnas no relevantes como `FECHA_APERTURA_TEXTO`.
  - Generaci√≥n y guardado de un dataset limpio en Parquet (`data/processed/igac_cleaned.parquet`).
- [x] **Estandarizaci√≥n b√°sica de valores monetarios** (parte de OE1, notebook `03_estandarizacion.ipynb`):
  - C√°lculo de `VALOR_AJUSTADO` usando IPC anual (`IPC_DATA`) con a√±o base definido en `BASE_YEAR`.
- [x] **Campos temporales y claves derivadas**:
  - Derivaci√≥n de campos como `YEAR_RADICA`, `MES_RADICA`, `TRIMESTRE_RADICA`, `SEMESTRE_RADICA`, `DIA_SEMANA_RADICA`.
  - Creaci√≥n de clave geogr√°fica `GEO_KEY = DEPARTAMENTO_MUNICIPIO`.

#### Pendientes dentro de Fase 1

- [ ] Normalizaci√≥n detallada de nombres de municipios (ej. "Bogot√° D.C." vs "Bogot√°").
- [ ] Revisi√≥n/normalizaci√≥n adicional de `DIVIPOLA` donde aplique.
- [ ] Limpieza espec√≠fica de campos de √°rea (si se integran en versiones futuras del dataset).

### üîÑ Fase 2: Detecci√≥n Basada en Reglas y Estad√≠stica

**Estado**: üß© En dise√±o / pendiente de implementaci√≥n en c√≥digo.

Seg√∫n `docs/task.md`, esta fase debe incluir:

- [ ] **Reglas de negocio (Hard Rules)**:
  - Regla de Rango: valor < 10% del aval√∫o catastral.
  - Regla de Tiempo: m√°s de 2 ventas en menos de 6 meses.
  - Regla de Integridad: valor > 0 con √°reas = 0.
- [ ] **Detecci√≥n estad√≠stica (Z-Score)**:
  - C√°lculo de Z-Score del precio por m¬≤ por municipio.
  - Marcaci√≥n de transacciones con |Z| > 3 como posibles anomal√≠as.

La estructura de datos generada en Fase 1 (valores ajustados, campos temporales y `GEO_KEY`) ya deja preparada la base para implementar estas reglas en los siguientes notebooks/scripts.

### üîÆ Fases Futuras

- **Fase 4**: Modelado de detecci√≥n de anomal√≠as
- **Fase 5**: Implementaci√≥n de alertas y monitoreo
- **Fase 6**: Dashboard y visualizaci√≥n
- **Fase 7**: Reportes y documentaci√≥n

## üìÅ Estructura del Proyecto

```
igac-anomalias-inmobiliarias/
‚îú‚îÄ‚îÄ data/                      # Datos (no versionados en Git)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                   # Datos crudos originales
‚îÇ   ‚îú‚îÄ‚îÄ processed/             # Datos procesados y estandarizados
‚îÇ   ‚îî‚îÄ‚îÄ models/                # Modelos entrenados
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                 # Jupyter notebooks de an√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploracion_inicial.ipynb    # An√°lisis exploratorio inicial
‚îÇ   ‚îú‚îÄ‚îÄ 02_limpieza_datos.ipynb         # Proceso de limpieza de datos
‚îÇ   ‚îú‚îÄ‚îÄ 03_estandarizacion.ipynb        # Estandarizaci√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ 04_entrenamiento_model.ipynb    # Entrenamiento de modelos
‚îÇ   ‚îú‚îÄ‚îÄ 05_deteccion_anomalias.ipynb    # Detecci√≥n de anomal√≠as
‚îÇ   ‚îî‚îÄ‚îÄ 06_analisis_texto_nlp.ipynb     # An√°lisis de texto con NLP
‚îÇ
‚îú‚îÄ‚îÄ src/                       # C√≥digo fuente Python
‚îÇ   ‚îú‚îÄ‚îÄ etl/                   # Pipeline de ETL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_cleaner.py    # Limpieza de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py     # Carga de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalizer.py      # Normalizaci√≥n de datos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validators.py      # Validaci√≥n de datos
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                 # Utilidades y helpers
‚îÇ
‚îú‚îÄ‚îÄ docs/                      # Documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ task.md                # Fases y procesos del reto
‚îÇ   ‚îî‚îÄ‚îÄ documentation.md       # Documentaci√≥n detallada
‚îÇ
‚îú‚îÄ‚îÄ README.md                  # Este archivo
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias de Python
‚îî‚îÄ‚îÄ pyproject.toml            # Configuraci√≥n de Poetry (si se usa)
```

## üîß Instalaci√≥n

### Requisitos Previos

- Python 3.8 o superior
- Git
- (Opcional) Poetry para gesti√≥n de dependencias

### Configuraci√≥n del Entorno

1. **Clonar el repositorio**

   ```bash
   git clone <repository-url>
   cd igac-anomalias-inmobiliarias
   ```

2. **Configurar entorno virtual (recomendado)**

   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\activate
   
   # Linux/MacOS
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Instalar dependencias**

   ```bash
   pip install -r requirements.txt
   
   # O usando Poetry (si est√° configurado)
   poetry install
   ```

4. **Configurar variables de entorno**
   Crear un archivo `.env` en la ra√≠z del proyecto con las siguientes variables:

   ```
   # Rutas de datos
   RAW_DATA_PATH=./data/raw/
   PROCESSED_DATA_PATH=./data/processed/
   MODELS_PATH=./data/models/
   
   # Configuraci√≥n de procesamiento
   NUM_WORKERS=4  # N√∫mero de workers para procesamiento paralelo
   CHUNK_SIZE=100000  # Tama√±o de chunks para procesamiento
   ```

## üöÄ Uso

### Cargar y procesar datos

1. **Cargar datos crudos**

   ```python
   from src.etl.data_loader import load_raw_data
   
   # Cargar datos en modo lazy (recomendado para conjuntos grandes)
   df = load_raw_data(lazy=True)
   ```

2. **Ejecutar limpieza de datos**

   ```python
   from src.etl.data_cleaner import clean_data
   
   # Limpiar datos
   df_cleaned = clean_data(df)
   ```

3. **Ejecutar notebooks de an√°lisis**
   Los notebooks est√°n numerados en orden secuencial:
   - `01_exploracion_inicial.ipynb`: An√°lisis exploratorio inicial
   - `02_limpieza_datos.ipynb`: Proceso de limpieza de datos
   - `03_estandarizacion.ipynb`: Estandarizaci√≥n de datos
   - `04_entrenamiento_model.ipynb`: Entrenamiento de modelos
   - `05_deteccion_anomalias.ipynb`: Detecci√≥n de anomal√≠as
   - `06_analisis_texto_nlp.ipynb`: An√°lisis de texto con NLP

## üìù Notas Importantes

### Rendimiento

- **Volumen de datos**: El conjunto completo contiene ~34 millones de registros
- **Uso de memoria**: Se recomienda al menos 16GB de RAM para procesamiento
- **Procesamiento en chunks**: Las funciones principales soportan procesamiento por lotes

### Calidad de Datos

- **Nombres de municipios**: Se han normalizado variaciones (ej: "Bogot√° D.C." ‚Üí "Bogot√°")
- **Valores faltantes**: Se han manejado siguiendo estrategias documentadas
- **Validaciones**: Se incluyen validaciones de integridad en `src/etl/validators.py`

### Consideraciones T√©cnicas

- **Reproducibilidad**: Se recomienda usar entornos virtuales
- **Versionado**: Se sigue Semantic Versioning (SemVer) para el c√≥digo
- **Documentaci√≥n**: La documentaci√≥n se actualiza con cada cambio significativo

## Autores

- Juan Carlos Charfuelan
- Keyla Daniela Cartagena
- Dylber Denylson Cabrera

---

**√öltima actualizaci√≥n**: 2025-11-25
