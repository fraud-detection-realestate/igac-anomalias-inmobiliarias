# Instituto de Monitoreo y Detecci√≥n de Anomal√≠as en Din√°mica Inmobiliaria en Colombia

## üìã Descripci√≥n del Proyecto

Sistema de an√°lisis y detecci√≥n de anomal√≠as en transacciones inmobiliarias en Colombia, utilizando datos hist√≥ricos del IGAC (Instituto Geogr√°fico Agust√≠n Codazzi) del per√≠odo 2015-2025. El proyecto tiene como objetivo identificar patrones irregulares en el mercado inmobiliario que puedan indicar fraude, lavado de activos o manipulaci√≥n de precios.

## üéØ Objetivos

- **Monitoreo continuo**: An√°lisis de ~34 millones de registros de transacciones inmobiliarias
- **Detecci√≥n de anomal√≠as**: Identificaci√≥n de patrones irregulares en precios, vol√∫menes y comportamientos
- **Normalizaci√≥n de datos**: Estandarizaci√≥n de informaci√≥n para an√°lisis comparativo entre regiones y per√≠odos
- **An√°lisis temporal**: Seguimiento de la evoluci√≥n del mercado inmobiliario colombiano

Este repositorio implementa de forma incremental las **fases definidas en `docs/task.md`**, apoy√°ndose en la descripci√≥n general de objetivos en `docs/documentation.md`.

## üõ†Ô∏è Stack Tecnol√≥gico

### Procesamiento de Datos

- **Python**: Lenguaje principal para an√°lisis y procesamiento
- **Polars/Dask**: Manejo eficiente de grandes vol√∫menes de datos (preferido sobre Pandas para 34M+ filas)
- **SQL**: Almacenamiento y consultas estructuradas

### An√°lisis y Visualizaci√≥n

- **Estad√≠stica descriptiva**: C√°lculo de m√©tricas por municipio y regi√≥n
- **Machine Learning**: Modelos de detecci√≥n de anomal√≠as (a definir)

## üîÑ Flujo de Datos (ETL)

Resumen del recorrido de los datos desde la fuente cruda hasta el dataset estandarizado listo para an√°lisis:

1. **Datos crudos (`data/raw/`)**
   - Descarga del hist√≥rico de transacciones inmobiliarias 2015‚Äì2025 (~34M registros) desde la fuente del IGAC.
   - Formato original (CSV u otro) sin limpieza.

2. **Dataset limpio (`data/processed/igac_cleaned.parquet`)**
   - Generado en el notebook `02_limpieza_datos.ipynb` usando `etl.data_cleaner.apply_all_cleaning`.
   - Operaciones clave:
     - Limpieza de columnas string y normalizaci√≥n de municipios/departamentos.
     - Estandarizaci√≥n de fechas a formato `dd/mm/YYYY`.
     - Limpieza de valores num√©ricos (incluyendo `VALOR`).
     - Manejo de nulos e imputaciones espec√≠ficas (folios, n√∫meros catastrales).
     - Eliminaci√≥n de duplicados por `PK`.
   - Formato **Parquet** optimizado para lectura con Polars (aprox. decenas de GB, seg√∫n compresi√≥n).

3. **Dataset estandarizado (`data/processed/igac_standardized.parquet`)**
   - Generado en el notebook `03_estandarizacion.ipynb` usando `etl.normalizer.apply_all_standardization`.
   - Operaciones clave:
     - C√°lculo de `VALOR_AJUSTADO` por inflaci√≥n usando `IPC_DATA` y `BASE_YEAR`.
     - Creaci√≥n de campos temporales derivados (`MES_RADICA`, `TRIMESTRE_RADICA`, etc.).
     - Generaci√≥n de clave geogr√°fica `GEO_KEY = DEPARTAMENTO_MUNICIPIO`.
   - Este dataset es la base para:
     - Reglas de negocio y Z-Score (Fase 2).
     - Modelos de ML y an√°lisis geoespacial (fases posteriores).

## üìä Estructura del Dataset

### Campos Principales

| Campo | Descripci√≥n |
|-------|-------------|
| `PK` | Identificador √∫nico |
| `MATRICULA` | N√∫mero de matr√≠cula inmobiliaria |
| `FECHA_RADICA_TEXTO` | Fecha de radicaci√≥n |
| `FECHA_APERTURA_TEXTO` | Fecha de apertura |
| `YEAR_RADICA` | A√±o de radicaci√≥n |
| `ORIP` | Oficina de Registro de Instrumentos P√∫blicos |
| `DIVIPOLA` | C√≥digo de divisi√≥n pol√≠tico-administrativa |
| `DEPARTAMENTO` | Departamento |
| `MUNICIPIO` | Municipio |
| `TIPO_PREDIO_ZONA` | Tipo de predio y zona |
| `CATEGORIA_RURALIDAD` | Categor√≠a rural/urbana |
| `NUM_ANOTACION` | N√∫mero de anotaci√≥n |
| `ESTADO_FOLIO` | Estado del folio |
| `FOLIOS_DERIVADOS` | Folios derivados |
| `Din√°mica_Inmobiliaria` | Tipo de din√°mica |
| `COD_NATUJUR` | C√≥digo naturaleza jur√≠dica |
| `NOMBRE_NATUJUR` | Nombre naturaleza jur√≠dica |
| `NUMERO_CATASTRAL` | N√∫mero catastral actual |
| `NUMERO_CATASTRAL_ANTIGUO` | N√∫mero catastral anterior |
| `DOCUMENTO_JUSTIFICATIVO` | Documento justificativo |
| `COUNT_A` | Contador A |
| `COUNT_DE` | Contador DE |
| `PREDIOS_NUEVOS` | Indicador de predios nuevos |
| `TIENE_VALOR` | Indicador de valor presente |
| `TIENE_MAS_DE_UN_VALOR` | Indicador de m√∫ltiples valores |
| `VALOR` | Valor de la transacci√≥n (campo num√©rico principal para an√°lisis) |

---

## üö¶ Estado por Fases (seg√∫n `docs/task.md`)

### ‚úÖ Fase 1: Cimientos de Datos y "Zona Cero"

**Estado**: ‚úÖ Implementada en los notebooks `02_limpieza_datos.ipynb` y `03_estandarizacion.ipynb` (parte de OE1).

#### Actividades principales

- [x] **Ingesta y carga eficiente**:
  - Uso de `Polars` en modo *lazy* para cargar ~30M de registros (`load_full_dataset_lazy`).
  - Exploraci√≥n de esquema y conteo de nulos por columna sin cargar todo en memoria.
- [x] **Limpieza inicial de datos** (notebook `02_limpieza_datos.ipynb` + `etl/data_cleaner.apply_all_cleaning`):
  - Eliminaci√≥n de comillas dobles en columnas de texto.
  - Manejo de columnas con alta proporci√≥n de nulos.
  - Depuraci√≥n de columnas no relevantes como `FECHA_APERTURA_TEXTO`.
  - Generaci√≥n y guardado de un dataset limpio en Parquet (`data/processed/igac_cleaned.parquet`).
- [x] **Estandarizaci√≥n b√°sica de valores monetarios** (parte de OE1, notebook `03_estandarizacion.ipynb`):
  - C√°lculo de `VALOR_AJUSTADO` usando IPC anual (`IPC_DATA`) con a√±o base definido en `BASE_YEAR`.
- [x] **Campos temporales y claves derivadas**:
  - Derivaci√≥n de campos como `YEAR_RADICA`, `MES_RADICA`, `TRIMESTRE_RADICA`, `SEMESTRE_RADICA`, `DIA_SEMANA_RADICA`.
  - Creaci√≥n de clave geogr√°fica `GEO_KEY = DEPARTAMENTO_MUNICIPIO`.

#### Pendientes dentro de Fase 1

- [ ] Normalizaci√≥n detallada de nombres de municipios (ej. "Bogot√° D.C." vs "Bogot√°").
- [ ] Revisi√≥n/normalizaci√≥n adicional de `DIVIPOLA` donde aplique.
- [ ] Limpieza espec√≠fica de campos de √°rea (si se integran en versiones futuras del dataset).

### üîÑ Fase 2: Detecci√≥n Basada en Reglas y Estad√≠stica

**Estado**: üß© En dise√±o / pendiente de implementaci√≥n en c√≥digo.

Seg√∫n `docs/task.md`, esta fase debe incluir:

- [ ] **Reglas de negocio (Hard Rules)**:
  - Regla de Rango: valor < 10% del aval√∫o catastral.
  - Regla de Tiempo: m√°s de 2 ventas en menos de 6 meses.
  - Regla de Integridad: valor > 0 con √°reas = 0.
- [ ] **Detecci√≥n estad√≠stica (Z-Score)**:
  - C√°lculo de Z-Score del precio por m¬≤ por municipio.
  - Marcaci√≥n de transacciones con |Z| > 3 como posibles anomal√≠as.

La estructura de datos generada en Fase 1 (valores ajustados, campos temporales y `GEO_KEY`) ya deja preparada la base para implementar estas reglas en los siguientes notebooks/scripts.

### üîÆ Fases Futuras

- **Fase 4**: Modelado de detecci√≥n de anomal√≠as
- **Fase 5**: Implementaci√≥n de alertas y monitoreo
- **Fase 6**: Dashboard y visualizaci√≥n
- **Fase 7**: Reportes y documentaci√≥n

## üìÅ Estructura del Proyecto

```text
fraud-detection-realestate/
‚îú‚îÄ‚îÄ README.md                  # Este archivo
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias Python
‚îú‚îÄ‚îÄ data/                      # Datos (no versionados)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                   # Datos crudos
‚îÇ   ‚îú‚îÄ‚îÄ processed/             # Datos procesados (ej. igac_cleaned.parquet, igac_standardized.parquet)
‚îÇ   ‚îî‚îÄ‚îÄ results/               # Resultados de an√°lisis
‚îú‚îÄ‚îÄ notebooks/                 # Jupyter notebooks (02_limpieza_datos, 03_estandarizacion, etc.)
‚îú‚îÄ‚îÄ src/                       # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ etl/                   # Scripts de ETL (carga, limpieza, estandarizaci√≥n)
‚îÇ   ‚îú‚îÄ‚îÄ analysis/              # Scripts de an√°lisis y reglas de negocio (Fase 2+)
‚îÇ   ‚îî‚îÄ‚îÄ models/                # Modelos de ML (Fase 3+)
‚îî‚îÄ‚îÄ docs/                      # Documentaci√≥n adicional
    ‚îú‚îÄ‚îÄ task.md                # Fases y procesos del reto
    ‚îî‚îÄ‚îÄ documentation.md       # Descripci√≥n y objetivos del sistema
```

## üîß Instalaci√≥n

```bash
# Clonar el repositorio
git clone <repository-url>
cd fraud-detection-realestate

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

## üìù Notas Importantes

- **Volumen de datos**: ~30 millones de registros requieren optimizaci√≥n en procesamiento
- **Ajuste inflacionario**: Cr√≠tico para comparaciones temporales v√°lidas
- **Calidad de datos**: Se esperan inconsistencias en nombres de municipios y formatos

## ü§ù Contribuciones

Este proyecto est√° en desarrollo activo. Las contribuciones son bienvenidas siguiendo las mejores pr√°cticas de an√°lisis de datos y detecci√≥n de fraude.

---

**√öltima actualizaci√≥n**: 2025-11-25
