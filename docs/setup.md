# GuÃ­a de ConfiguraciÃ³n - Fraud Detection Real Estate

## ğŸ“‹ Requisitos Previos

- Python 3.9 o superior
- Entorno virtual (venv) ya configurado
- Dataset IGAC_2015_-_2023.csv en `data/raw/`

## ğŸš€ InstalaciÃ³n

### 1. Activar el Entorno Virtual

```powershell
# En Windows PowerShell
.\venv\Scripts\Activate.ps1

# O en CMD
.\venv\Scripts\activate.bat
```

### 2. Instalar Dependencias

```powershell
pip install -r requirements.txt
```

Esto instalarÃ¡:

- **Polars** - Procesamiento eficiente de datos
- **Pandas** - AnÃ¡lisis complementario
- **PyArrow** - Formato Parquet
- **Jupyter** - Notebooks interactivos
- **Matplotlib/Seaborn** - VisualizaciÃ³n
- **Great Expectations** - ValidaciÃ³n de calidad

### 3. Verificar InstalaciÃ³n

```powershell
python -c "import polars; print(f'Polars {polars.__version__} instalado correctamente')"
```

## ğŸ“Š Estructura del Proyecto

```
fraud-detection-realestate/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # IGAC_2015_-_2023.csv
â”‚   â”œâ”€â”€ processed/              # Datos procesados (Parquet)
â”‚   â”œâ”€â”€ interim/                # Datos intermedios
â”‚   â””â”€â”€ external/               # Datos externos (IPC, etc.)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploracion_inicial.ipynb
â”‚   â”œâ”€â”€ 02_limpieza_datos.ipynb
â”‚   â”œâ”€â”€ 03_estandarizacion.ipynb
â”‚   â””â”€â”€ 04_validacion_calidad.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ data_loader.py      # Carga eficiente de datos
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py     # Limpieza y normalizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ normalizer.py       # EstandarizaciÃ³n y ajuste IPC
â”‚   â”‚   â””â”€â”€ validators.py       # ValidaciÃ³n de calidad
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ config.py            # ConfiguraciÃ³n y constantes
â””â”€â”€ requirements.txt
```

## ğŸ”§ Uso de los Notebooks

### Notebook 1: ExploraciÃ³n Inicial

**Objetivo**: Entender la estructura del dataset

```powershell
jupyter notebook notebooks/01_exploracion_inicial.ipynb
```

**Contenido**:

- InformaciÃ³n general del dataset
- AnÃ¡lisis de tipos de datos
- Valores nulos
- DistribuciÃ³n temporal y geogrÃ¡fica
- AnÃ¡lisis de valores monetarios

### Notebook 2: Limpieza de Datos

**Objetivo**: Limpiar y preparar los datos

```powershell
jupyter notebook notebooks/02_limpieza_datos.ipynb
```

**Contenido**:

- Carga del dataset completo (lazy loading)
- NormalizaciÃ³n de municipios y departamentos
- Parseo de fechas
- Limpieza de valores numÃ©ricos
- EliminaciÃ³n de duplicados
- Guardado en formato Parquet

**âš ï¸ Nota**: Este notebook procesa ~9.5 GB de datos y puede tomar varios minutos.

### Notebook 3: EstandarizaciÃ³n

**Objetivo**: Estandarizar valores para comparabilidad

```powershell
jupyter notebook notebooks/03_estandarizacion.ipynb
```

**Contenido**:

- Ajuste de valores monetarios por IPC (2015-2024)
- CreaciÃ³n de campos temporales derivados
- NormalizaciÃ³n de cÃ³digos DIVIPOLA
- GeneraciÃ³n de clave geogrÃ¡fica
- CÃ¡lculo de mÃ©tricas adicionales

### Notebook 4: ValidaciÃ³n de Calidad

**Objetivo**: Validar la calidad del dataset procesado

```powershell
jupyter notebook notebooks/04_validacion_calidad.ipynb
```

**Contenido**:

- Reporte de calidad de datos
- ValidaciÃ³n de rangos
- DetecciÃ³n de outliers
- AnÃ¡lisis de completitud
- MÃ©tricas finales del dataset

## ğŸ” MÃ³dulos ETL

### data_loader.py

Funciones para carga eficiente de datos:

```python
from etl.data_loader import load_csv_sample, load_full_dataset_lazy, save_to_parquet

# Cargar muestra
sample = load_csv_sample(n_rows=10000)

# Cargar dataset completo (lazy)
lf = load_full_dataset_lazy()

# Guardar en Parquet
save_to_parquet(df, output_path)
```

### data_cleaner.py

Funciones de limpieza:

```python
from etl.data_cleaner import apply_all_cleaning

# Aplicar todas las limpiezas
df_clean = apply_all_cleaning(df)
```

### normalizer.py

Funciones de estandarizaciÃ³n:

```python
from etl.normalizer import apply_all_standardization

# Aplicar estandarizaciÃ³n
df_std = apply_all_standardization(df_clean)
```

### validators.py

Funciones de validaciÃ³n:

```python
from etl.validators import generate_quality_report, detect_outliers

# Generar reporte
report = generate_quality_report(df)

# Detectar outliers
df_outliers = detect_outliers(df, 'VALOR_AJUSTADO')
```

## ğŸ“ ConfiguraciÃ³n

El archivo `src/utils/config.py` contiene:

- **Rutas de archivos**: Ubicaciones de datos raw, procesados, etc.
- **ParÃ¡metros de procesamiento**: TamaÃ±o de chunks, muestras
- **Datos del IPC**: Ãndice de Precios al Consumidor 2015-2025
- **Mapeos**: NormalizaciÃ³n de municipios
- **Rangos vÃ¡lidos**: Para validaciÃ³n de datos

### Actualizar datos del IPC

Si necesitas actualizar los valores del IPC, edita `src/utils/config.py`:

```python
IPC_DATA = {
    2015: 100.0,
    2016: 107.5,
    # ... actualizar con datos reales del DANE
    2024: 160.0,
    2025: 168.0,
}
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "Module not found"

```powershell
# AsegÃºrate de estar en el entorno virtual
.\venv\Scripts\Activate.ps1

# Reinstala las dependencias
pip install -r requirements.txt
```

### Error: "Memory Error" al procesar dataset completo

El dataset es muy grande (~9.5 GB). Soluciones:

1. **Usar lazy loading**: Los notebooks ya lo implementan
2. **Procesar en chunks**: Ajustar `CHUNK_SIZE` en `config.py`
3. **Aumentar memoria virtual**: Configurar swap en Windows

### Error: "File not found" para IGAC CSV

Verifica que el archivo estÃ© en la ubicaciÃ³n correcta:

```powershell
# Debe estar en:
data/raw/IGAC_2015_-_2023.csv
```

## ğŸ“ˆ PrÃ³ximos Pasos

DespuÃ©s de completar la fase de ETL:

1. **Fase 3**: DefiniciÃ³n de la "Normalidad"
   - AnÃ¡lisis estadÃ­stico por municipio
   - Establecer lÃ­neas base

2. **Fase 4**: DetecciÃ³n de AnomalÃ­as
   - Implementar modelos de detecciÃ³n
   - Reglas de negocio

3. **Fase 5**: VisualizaciÃ³n y Monitoreo
   - Dashboard interactivo
   - Sistema de alertas

## ğŸ“ Soporte

Para problemas o preguntas:

- Revisar logs de Jupyter
- Verificar versiones de dependencias: `pip list`
- Consultar documentaciÃ³n de Polars: <https://pola-rs.github.io/polars/>

---

**Ãšltima actualizaciÃ³n**: 2025-11-22
